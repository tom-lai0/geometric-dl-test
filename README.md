## Introduction
  This program tries to perform a dimension reduction from a 3d object to a 2d plane.
  At the point, the 3d object is a point cloud of unit sphere.

  The loss functions used are kl divergence, reconstruction error and exponential inverse distance.
  The exponential inverse distance measures the difference between pairwise distance of original points and pairwise distance of encoded points.

## Experiment Results

### Figures

- ### 1. Mid-way Figures

    ![midway](https://github.com/tom-lai0/dl-test/blob/main/experiment_1/encoded_epoch_500.png)
    
    Images with name 'encoded_epoch_xxxx.png'.
    The images plots the encoded latent space during training at epoch no. xxxx.

    The colors in the images represent the original distribution.
    For example, the rightmost plot with title 'z' in the above represent the original z-coordinate.
    The original z-coordinate of yellow points are closed to 1, while the original z-coordinate of purple points are closed to -1.
    Similarly for the other two plots with titles 'x' or 'y'.
    A desired model should give plots that the colors of all 3 plots are well-separated.


- ### 2. Final Latent Space Figures

    ![final](https://github.com/tom-lai0/dl-test/blob/main/experiment_1/encoded.png)

    Images with name 'encoded.png'.
    The images plots the encoded latent space after training.

    The color have the same meaning as the mid-way figures.
    A desired model should give plots that the colors of all 3 plots are well-separated.

- ### 3. Loss History Plots

    ![loss-hist](https://github.com/tom-lai0/dl-test/blob/main/experiment_1/loss_history.png)

    Images with name 'loss_history.png', plot the history of the three loss values.
    The x-axis of these images are log(number_of_iterations). 

- ### 4. Projection of the Original Point Cloud
    
    ![origin-proj](https://github.com/tom-lai0/dl-test/blob/main/experiment_1/original.png)

    Images with name 'original.png'.
    The images plot the projections of the original 3d point cloud to 2d plane.

    For example, the leftmost plot with title 'z' plots the x-coordinate and y-coordinate of the original point cloud. And the colors of point reflect the z-coordinate. Yellow points have z-coordinate closed to 1, while purple points have z-coordinate closed to -1.

- ### 5. Projection of the Reconstructed Point Cloud

    ![recon-proj](https://github.com/tom-lai0/dl-test/blob/main/experiment_1/reconstruction.png)

    Images with name 'reconstruction.png'.
    The images plot the projections of the reconstructed 3d point cloud to 2d plane.

    The meaning of the plots are similar to (4). 
    If the model is well-trained with little reconstruction error, the images should look similar to (4).

### Observation, Problem or Improvement

- ### 1. 

    From the mid-way figures and final latent space figures, we can see that the color in plots with title 'z' is better sparated compared to 'x' and 'y'. A possible factor maybe the data generating mechanism. 
    
    The data are generated by sampling from two uniform distribution as two angle pheta and phi and then calculate (x, y, z) = (cos(phi) * sin(theta), sin(phi) * sin(theta), cos(theta)).
    The point cloud generated has a higher density around (x, y) = (0, 0). 
    We can also observe this effect from the scatter plots (projection of the original point cloud). 
    So the model tries to fit the z-coordinate better instead of x or y.

    An improvement is to use a uniform distribution on the surface of sphere.

- ### 2.

    From the loss history plots, we can see that the loss change a lot around e^5 iterations.
    The exponential inverse distance and reconstruction error decrease while the kl divergence increase.

    Also, as number of iterations increase, the variance of the loss increase.

    The reason is unknown at this point. We may train the model with a higher number of epochs to see the longer term effect of the loss.

- ### 3.

    From the mid-way figures and final latent space figures, we can see that most of the points are on the edge of a circle with radius around 1.7. 

    The reason is also unknown. But this maybe an effect of the increase of kl divergence. We may use cross validation to select the ratio between the 3 loss values.

- ### 4. 

    From the projection of the original point cloud and projection of the reconstructed point cloud, we can see that the performance of reconstruction is not so good. The reconstructed point cloud seems to be flat.

    A potential reason maybe that the encoded latent space do not separate the original points well.  

    
    



